{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382d0169-96ed-456b-9389-bf136ced7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingWarmRestarts, CyclicLR,_LRScheduler\n",
    "from performance_eval import whole_eval_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba78be5d-f415-42e4-87b2-fc1d4cd1172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    tb_log_dir = './tb_log/Transformer_CrossValid_cross{}/'.format(i)\n",
    "    if not os.path.exists(tb_log_dir):\n",
    "        os.mkdir(tb_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e0b6c-1294-4fa2-8dca-36789eaf5866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2df61e4-b7e7-43b2-9e58-660bd7a3ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "\n",
    "    \n",
    "    def __init__(self,\n",
    "                 optimizer : torch.optim.Optimizer,\n",
    "                 first_cycle_steps : int,\n",
    "                 cycle_mult : float = 1.,\n",
    "                 max_lr : float = 0.1,\n",
    "                 min_lr : float = 0.001,\n",
    "                 warmup_steps : int = 0,\n",
    "                 gamma : float = 1.,\n",
    "                 last_epoch : int = -1\n",
    "        ):\n",
    "        assert warmup_steps < first_cycle_steps\n",
    "        \n",
    "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
    "        self.base_max_lr = max_lr # first max learning rate\n",
    "        self.max_lr = max_lr # max learning rate in the current cycle\n",
    "        self.min_lr = min_lr # min learning rate\n",
    "        self.warmup_steps = warmup_steps # warmup step size\n",
    "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
    "        \n",
    "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle = 0 # cycle count\n",
    "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
    "        \n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "        # set learning rate min_lr\n",
    "        self.init_lr()\n",
    "\n",
    "    def init_lr(self):\n",
    "        self.base_lrs = []\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.min_lr\n",
    "            self.base_lrs.append(self.min_lr)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.step_in_cycle == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.step_in_cycle < self.warmup_steps:\n",
    "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.max_lr - base_lr) \\\n",
    "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
    "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.step_in_cycle = self.step_in_cycle + 1\n",
    "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
    "                self.cycle += 1\n",
    "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
    "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
    "        else:\n",
    "            if epoch >= self.first_cycle_steps:\n",
    "                if self.cycle_mult == 1.:\n",
    "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
    "                    self.cycle = epoch // self.first_cycle_steps\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
    "                    self.cycle = n\n",
    "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
    "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
    "            else:\n",
    "                self.cur_cycle_steps = self.first_cycle_steps\n",
    "                self.step_in_cycle = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_heads=8, hidden_dim=200, num_layers=6):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        gene2vec_weight = np.load('gene2vec.npy')\n",
    "        gene2vec_weight = np.concatenate((gene2vec_weight, np.zeros((1, gene2vec_weight.shape[1]))), axis=0)\n",
    "        gene2vec_weight = torch.from_numpy(gene2vec_weight.astype(np.float64))\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(gene2vec_weight)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc1 = nn.Linear(1000, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "    def forward(self, x):\n",
    "        # output = self.embedding(x)\n",
    "        # output = output.permute(1, 0, 2)  # 调整输入形状以适应Transformer模型\n",
    "        # output = self.transformer_encoder(x)\n",
    "        # output = output.mean(dim=0)  # 取平均值\n",
    "        output = self.fc1(x.float())\n",
    "        output = self.fc2(output)\n",
    "        return output\n",
    "\n",
    "# 自定义数据集类\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_file, label_file):\n",
    "        self.data = pd.read_csv(data_file).iloc[:, 1:].to_numpy().astype(np.int64)  # Convert to torch.long\n",
    "        self.labels = pd.read_csv(label_file).iloc[:,6].to_numpy().astype(np.int64)  # Convert to torch.long\n",
    "        # self.data = torch.DoubleTensor(self.data)\n",
    "        # self.labels= torch.DoubleTensor(self.labels)\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx],self.labels[idx]\n",
    "        # return torch.tensor(self.data[idx], dtype=torch.double), torch.tensor(self.labels[idx], dtype=torch.double)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "127e02ae-1365-4506-83f1-9621ebb63e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6595209389925003\n",
      "Epoch 11/100, Loss: 0.504757322371006\n",
      "Epoch 21/100, Loss: 0.4821956902742386\n",
      "Epoch 31/100, Loss: 0.44254909828305244\n",
      "Epoch 41/100, Loss: 0.43279799073934555\n",
      "Epoch 51/100, Loss: 0.40062373504042625\n",
      "Epoch 61/100, Loss: 0.36234208196401596\n",
      "Epoch 71/100, Loss: 0.33920204266905785\n",
      "Epoch 81/100, Loss: 0.33145179226994514\n",
      "Epoch 91/100, Loss: 0.3215184435248375\n",
      "Accuracy on test set: 85.41%\n",
      "Accuracy on test set: 74.83%\n",
      "Accuracy on test set: 75.89%\n",
      "Epoch 1/100, Loss: 0.6076017618179321\n",
      "Epoch 11/100, Loss: 0.49539998918771744\n",
      "Epoch 21/100, Loss: 0.4719289243221283\n",
      "Epoch 31/100, Loss: 0.42323895171284676\n",
      "Epoch 41/100, Loss: 0.41145552322268486\n",
      "Epoch 51/100, Loss: 0.37342918664216995\n",
      "Epoch 61/100, Loss: 0.3304347060620785\n",
      "Epoch 71/100, Loss: 0.30570539087057114\n",
      "Epoch 81/100, Loss: 0.2976483516395092\n",
      "Epoch 91/100, Loss: 0.28742471151053905\n",
      "Accuracy on test set: 89.36%\n",
      "Accuracy on test set: 75.52%\n",
      "Accuracy on test set: 75.52%\n",
      "Epoch 1/100, Loss: 0.6772160977125168\n",
      "Epoch 11/100, Loss: 0.5140571929514408\n",
      "Epoch 21/100, Loss: 0.492964044213295\n",
      "Epoch 31/100, Loss: 0.45702308788895607\n",
      "Epoch 41/100, Loss: 0.4483589455485344\n",
      "Epoch 51/100, Loss: 0.4193243868649006\n",
      "Epoch 61/100, Loss: 0.38450511917471886\n",
      "Epoch 71/100, Loss: 0.3631801940500736\n",
      "Epoch 81/100, Loss: 0.35600606352090836\n",
      "Epoch 91/100, Loss: 0.34674743562936783\n",
      "Accuracy on test set: 82.82%\n",
      "Accuracy on test set: 76.60%\n",
      "Accuracy on test set: 76.22%\n",
      "Epoch 1/100, Loss: 0.6662875115871429\n",
      "Epoch 11/100, Loss: 0.5088841915130615\n",
      "Epoch 21/100, Loss: 0.4866408705711365\n",
      "Epoch 31/100, Loss: 0.44847681373357773\n",
      "Epoch 41/100, Loss: 0.4392702989280224\n",
      "Epoch 51/100, Loss: 0.40921425074338913\n",
      "Epoch 61/100, Loss: 0.373788308352232\n",
      "Epoch 71/100, Loss: 0.3524070605635643\n",
      "Epoch 81/100, Loss: 0.345234751701355\n",
      "Epoch 91/100, Loss: 0.3361917808651924\n",
      "Accuracy on test set: 83.14%\n",
      "Accuracy on test set: 75.18%\n",
      "Accuracy on test set: 75.89%\n",
      "Epoch 1/100, Loss: 0.7240399420261383\n",
      "Epoch 11/100, Loss: 0.5205681100487709\n",
      "Epoch 21/100, Loss: 0.49866385012865067\n",
      "Epoch 31/100, Loss: 0.46286536008119583\n",
      "Epoch 41/100, Loss: 0.4543110243976116\n",
      "Epoch 51/100, Loss: 0.425537109375\n",
      "Epoch 61/100, Loss: 0.39082591608166695\n",
      "Epoch 71/100, Loss: 0.36934444308280945\n",
      "Epoch 81/100, Loss: 0.3620306998491287\n",
      "Epoch 91/100, Loss: 0.35264089703559875\n",
      "Accuracy on test set: 81.97%\n",
      "Accuracy on test set: 75.18%\n",
      "Accuracy on test set: 75.89%\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train_data = 'lookupcsv/CrossValid/cross{}/GWAS_train.csv'.format(i)\n",
    "    train_label = 'lookupcsv/CrossValid/cross{}/train.csv'.format(i)\n",
    "    train_dataset = CustomDataset(train_data, train_label)\n",
    "\n",
    "    valid_data = 'lookupcsv/CrossValid/cross{}/GWAS_valid.csv'.format(i)\n",
    "    valid_label = 'lookupcsv/CrossValid/cross{}/valid.csv'.format(i)\n",
    "    valid_dataset = CustomDataset(valid_data, valid_label)\n",
    "\n",
    "    test_data = 'lookupcsv/CrossValid/cross{}/GWAS_test.csv'.format(i)\n",
    "    test_label = 'lookupcsv/CrossValid/cross{}/test.csv'.format(i)\n",
    "    test_dataset = CustomDataset(test_data, test_label)\n",
    "\n",
    "    # 定义超参数\n",
    "    input_dim = 1000  # 特征数\n",
    "    output_dim = 2  # 类别数\n",
    "    num_epochs = 100\n",
    "    batch_size = 128\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "    # 初始化模型、损失函数和优化器\n",
    "    model = TransformerModel(input_dim, output_dim).to(\"cuda\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer,\n",
    "        first_cycle_steps=15,\n",
    "        cycle_mult=2,\n",
    "        max_lr=1e-4,\n",
    "        min_lr=1e-6,\n",
    "        warmup_steps=5,\n",
    "        gamma=0.9\n",
    "    )\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if epoch %10==0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "        scheduler.step()\n",
    "    # 在测试集上评估模型\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.shape)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test = predicted.unsqueeze(1)\n",
    "            outputs = torch.cat((outputs,test),dim=1)\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    all_outputs_cat = torch.cat(all_outputs, dim=0)\n",
    "    print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n",
    "    wwc = pd.DataFrame(all_outputs_cat)\n",
    "    wwc.columns = ['trans1','trans2','COG_pred']\n",
    "    wwc.to_csv('./tb_log/Transformer_CrossValid_cross{}/train_eval.csv'.format(i))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test = predicted.unsqueeze(1)\n",
    "            outputs = torch.cat((outputs,test),dim=1)\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    all_outputs_cat = torch.cat(all_outputs, dim=0)\n",
    "    print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n",
    "    wwc = pd.DataFrame(all_outputs_cat)\n",
    "    wwc.columns = ['trans1','trans2','COG_pred']\n",
    "    wwc.to_csv('./tb_log/Transformer_CrossValid_cross{}/test_eval.csv'.format(i))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test = predicted.unsqueeze(1)\n",
    "            outputs = torch.cat((outputs,test),dim=1)\n",
    "            # print(outputs.shape,predicted.shape)\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    all_outputs_cat = torch.cat(all_outputs, dim=0)\n",
    "    print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n",
    "    wwc = pd.DataFrame(all_outputs_cat)\n",
    "    wwc.columns = ['trans1','trans2','COG_pred']\n",
    "    wwc.to_csv('./tb_log/Transformer_CrossValid_cross{}/valid_eval.csv'.format(i))\n",
    "    \n",
    "    data = pd.read_csv('./tb_log/Transformer_CrossValid_cross{}/train_eval.csv'.format(i))\n",
    "    data2 = pd.read_csv('lookupcsv/CrossValid/cross{}/train.csv'.format(i))['ADD']\n",
    "    data['COG'] = data2\n",
    "    data=data.fillna(0)\n",
    "    data.to_csv('./tb_log/Transformer_CrossValid_cross{}/train_eval.csv'.format(i),index=False)\n",
    "    \n",
    "    data = pd.read_csv('./tb_log/Transformer_CrossValid_cross{}/test_eval.csv'.format(i))\n",
    "    data2 = pd.read_csv('lookupcsv/CrossValid/cross{}/test.csv'.format(i))['ADD']\n",
    "    data['COG'] = data2\n",
    "    data=data.fillna(0)\n",
    "    data.to_csv('./tb_log/Transformer_CrossValid_cross{}/test_eval.csv'.format(i),index=False)\n",
    "    \n",
    "    data = pd.read_csv('./tb_log/Transformer_CrossValid_cross{}/valid_eval.csv'.format(i))\n",
    "    data2 = pd.read_csv('lookupcsv/CrossValid/cross{}/valid.csv'.format(i))['ADD']\n",
    "    data['COG'] = data2\n",
    "    data=data.fillna(0)\n",
    "    data.to_csv('./tb_log/Transformer_CrossValid_cross{}/valid_eval.csv'.format(i),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c050176-17fc-4000-a4ad-044b21c465df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20506f17-c0d6-4d84-80b8-fc492df40c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb6ad811-503c-47d1-8813-7aa5f6222fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ecf71b8-6de4-44d7-9d35-5b0181f43a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans1</th>\n",
       "      <th>trans2</th>\n",
       "      <th>COG_score</th>\n",
       "      <th>COG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.449643</td>\n",
       "      <td>0.496058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.120944</td>\n",
       "      <td>0.148253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.276933</td>\n",
       "      <td>0.228604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.531295</td>\n",
       "      <td>-0.387797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>420</td>\n",
       "      <td>1.238858</td>\n",
       "      <td>-0.906573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>2.393188</td>\n",
       "      <td>-1.505869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>1.454986</td>\n",
       "      <td>-1.096195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>1.876705</td>\n",
       "      <td>-1.252171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>1.111280</td>\n",
       "      <td>-0.779981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    trans1    trans2  COG_score  COG\n",
       "0             0 -0.449643  0.496058        1.0  1.0\n",
       "1             1  0.120944  0.148253        1.0  1.0\n",
       "2             2 -0.276933  0.228604        1.0  1.0\n",
       "3             3  0.048918  0.005690        0.0  1.0\n",
       "4             4  0.531295 -0.387797        0.0  1.0\n",
       "..          ...       ...       ...        ...  ...\n",
       "420         420  1.238858 -0.906573        0.0  0.0\n",
       "421         421  2.393188 -1.505869        0.0  0.0\n",
       "422         422  1.454986 -1.096195        0.0  0.0\n",
       "423         423  1.876705 -1.252171        0.0  0.0\n",
       "424         424  1.111280 -0.779981        0.0  0.0\n",
       "\n",
       "[425 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d43456-384e-4715-96dd-f88ac9e1a30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1dc6bae-2168-46e7-b00c-00bb69357910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# train_data = pd.read_csv('lookupcsv/CrossValid/cross0/GWAS_train.csv').iloc[:,1:].to_numpy().T\n",
    "# # df = pd.read_csv(dataset_path+\"train_data.csv\")\n",
    "# gene_names = [str(gene) for gene in range(train_data.shape[0])]\n",
    "# model = Word2Vec([gene_names], vector_size=200, window=10, min_count=0, workers=4)\n",
    "# np.save('gene2vec.npy',model.wv.vectors)\n",
    "# # time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "# # print('-----finished -----',time) \n",
    "# test_data = pd.read_csv('lookupcsv/CrossValid/cross0/GWAS_test.csv').iloc[:,1:].to_numpy()\n",
    "# test_label = pd.read_csv('lookupcsv/CrossValid/cross0/test.csv').iloc[:,5].to_numpy()\n",
    "# pred = model.predict(test_data)\n",
    "# (pred==test_label).sum()/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105cc03-8f0c-49fa-a0dc-90fe47b92b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1d3ab-1120-4531-bad3-d249ea44b9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a44155-2403-4cdc-ab40-5b8a3f982202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89dd327-6d00-4365-8bf4-4f67a89a79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('lookupcsv/CrossValid/cross0/train.csv')\n",
    "train_data=[]\n",
    "\n",
    "train_data.append(data_train.iloc[:,1:])\n",
    "# for i, task in enumerate(self.tasks):\n",
    "#     self.train_data[i] = self.preprocess_pipeline(self.train_data[i], task)\n",
    "#     print('after preprocess pipeline, the data frame for the {} task is'.format(task))\n",
    "#     print(self.train_data[i])\n",
    "#     print('\\n' * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bde75a-fd99-4d41-bb5e-4b257358214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56bb45-9627-4dcc-8196-c4c62ea21a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
